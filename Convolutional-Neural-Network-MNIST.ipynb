{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "![](https://raw.githubusercontent.com/whoisraibolt/Convolutional-Neural-Network-MNIST/master/images/Alexandra-Raibolt-Avatar.png)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<div style=\"text-align:center\">\n",
    "**ALEXANDRA RAIBOLT**\n",
    "</div>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<div style=\"text-align:center\">\n",
    "MSc Student @ IME​ and​ BI & Data Management @ Firjan\n",
    "</div>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Construa sua própria Rede Neural Convolucional em 3, 2, 1...!"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<div style=\"text-align:justify\">Uma introdução as Redes Neurais Convolucionais em Python, usando o framework TensorFlow com Keras.</div>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Visão Geral"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<div style=\"text-align:justify\">Este Jupyter Notebook mostra passo a passo, o processo de construção de uma Rede Neural Convolucional para reconhecimento e clasificação de Dígitos Manuscritos em Python, usando o framework TensorFlow com Keras.</div>\n",
    "<br>\n",
    "<div style=\"text-align:justify\">Neste exemplo, usamos o conjunto de dados [MNIST](http://yann.lecun.com/exdb/mnist \"MNIST\").</div>\n",
    "<br>\n",
    "<div style=\"text-align:justify\">**Aviso prévio:**</div>\n",
    "<br>\n",
    "<div style=\"text-align:justify\">O modelo de Redes Neurais Convolucional proposto nesta palestra foi implementado em Python (versão 5.4.0) usando o framework TensorFlow (versão 1.4.0) com Keras (versão 2.2.4) usando uma arquitetura baseada em GPU, e pode não funcionar com outras versões.</div>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Requisitos"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- Python 3 (versão 5.4.0);\n",
    "- TensorFlow (versão 1.4.0);\n",
    "- Keras (versão 2.2.4);\n",
    "- Jupyter Notebook (versão 4.4.0)."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Dependências"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- matplotlib;\n",
    "- numpy.\n",
    "\n",
    "<div style=\"text-align:justify\">Você pode instalar dependências ausentes com [pip](https://pip.pypa.io/en/stable \"pip\"). E instalar o TensorFlow via [TensorFlow](https://www.tensorflow.org/install \"TensorFlow\") link.</div>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## O que é Aprendizado de Máquina?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<div style=\"text-align:justify\">Aprendizado de Máquina (em inglês, *Machine Learning*) é uma subárea da Inteligencia Artifical que tem como propósito automatizar máquinas através da criação de modelos analíticos. Tal ideia se baseia na premissa de que máquinas tem a habilidade de aprender, tomar decisões, extrair *insights* e reconhecer padrões (através de dados) sem a necessidade de serem explicitamente programadas, ou seja, sem interferência humana.</div>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Tipos de Aprendizado de Máquina:"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "![Tipos de Aprendizado de Maquina](https://raw.githubusercontent.com/whoisraibolt/MNIST-Convolutional-Neural-Network/master/images/Tipos-de-Aprendizado-de-Maquina.png)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Aprendizado Supervisionado:"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<div style=\"text-align:justify\">Um conjunto de dados de entradas e suas respectivas saídas desejadas (denominadas como classes) são fornecidas por um “professor” ao modelo/computador, mostrando que há relação entre os dados de entrada e de saída.</div>\n",
    "<br>\n",
    "<div style=\"text-align:justify\">O objetivo deste tipo de aprendizado está em mapear as entradas para as suas respectivas saídas desejadas ao encontrar uma regra geral que seja apta a classificar novos dados entre as classes já presentes no conjunto de dados.</div>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Classificação:"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<div style=\"text-align:justify\">Em uma tarefa de classificação, o objetivo é mapear os tipos de entradas e categoriza-las em classes distintas, ou seja, realiza previsões onde os resultados de saída são de natureza discreta.</div>\n",
    "<br>\n",
    "<div style=\"text-align:justify\">Algoritmos de classificação podem ser usados para problemas como: classificação de gênero, classificação de imagens médicas, classificação de expressões faciais, etc.</div>\n",
    "<br>\n",
    "<div style=\"text-align:justify\">K-vizinhos mais próximos, Máquinas de Vetores de Suporte e Redes Neurais Convolucionais são exemplos de algoritmos de classificação.</div>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## O que é Rede Neural Artificial?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<div style=\"text-align:justify\">Tendo como exemplo, a identificação de objetos e ambientes distintos, é questionado como o cérebro humano é capaz de traduzir uma imagem na retina humana para algo onde um indivíduo consiga identificar e classificar.</div>\n",
    "<br>\n",
    "<div style=\"text-align:justify\">Compreendendo toda a complexidade do cérebro humano, tornou-se necessário o estudo e compreensão de como os sistemas neurais biológicos funcionam, e a partir de tais estudos, pesquisadores foram capazes de proporcionar a estrutura básica para a construção de modelos de Redes Neurais Artificiais (em inglês, *Artificial Neural Networks - ANN*).</div>\n",
    "<br>\n",
    "<div style=\"text-align:justify\"></div>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## O que é Rede Neural Convolucional?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<div style=\"text-align:justify\">As diversas arquiteturas de Redes Neurais Convolucionais são aplicadas com sucesso em desafios de reconhecimentoe classificação de imagens, embora sejam também utilizadas em processamento de vídeo, e Processamento de Linguagem Natural (em inglês, *Natural Language Processing*).</div>\n",
    "<br>\n",
    "<div style=\"text-align:justify\">Uma Rede Neural Convolucional pode ser caracterizada como sendo uma ANN de múltiplas camadas onde primariamente faz-se a suposição de que os dados de entrada sejam imagens.</div>\n",
    "<br>\n",
    "<div style=\"text-align:justify\">As Redes Neurais Convolucionais hoje, são consideradas estado-da-arte para a resolução de problemas na área de Visão Computacional, possuindo uma variedade de modelos e de arquiteturas (AlexNet, Inception, ResNet, etc.)</div>\n",
    "<br>\n",
    "<div style=\"text-align:justify\">Uma arquitetura básica de CNN pode ser dividida em camadas.</div>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Arquitetura de uma Rede Neural Convolucional"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "![Arquitetura de uma Rede Neural Convolucional](https://raw.githubusercontent.com/whoisraibolt/Convolutional-Neural-Network-MNIST/master/images/Arquitetura-CNN.png)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Camada de Entrada (ou em inglês, Input Layer)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<div style=\"text-align:justify\">Onde a imagem (ou base de imagens) é inserida na rede.</div>\n",
    "<br>\n",
    "<div style=\"text-align:justify\">Computacionalmente falando, toda imagem pode ser representada como sendo uma matriz de valores de pixel, como pode ser visto abaixo:</div>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "![Camada de Entrada](https://raw.githubusercontent.com/whoisraibolt/Convolutional-Neural-Network-MNIST/master/images/Camada-de-Entrada.png)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<div style=\"text-align:justify\">Portanto, ao receber uma imagem em escala de cinza como entrada, o computador \"enxergará\" uma matriz de valores de pixel (*m* x *n* x *1*), onde o valor 1 refere-se a um componente pré-estabelecido de uma imagem – Canal - neste caso o valor 1 refere-se a uma imagem em escala de cinza. Portanto, será atribuído valores de intensidade de pixels dentro do intervalode 0 à 255 (onde 0 representa pontos pretos e 255 representa pontos brancos) para cada ponto da matriz.</div>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Mãos a obra!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using TensorFlow backend.\n"
     ]
    }
   ],
   "source": [
    "# Imports\n",
    "from keras.datasets import mnist\n",
    "from keras.layers import Conv2D, MaxPooling2D\n",
    "from keras.layers import Dense, Dropout, Flatten\n",
    "from keras.models import Sequential\n",
    "from keras.optimizers import Adam\n",
    "import keras\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Dimensions of the data\n",
    "\n",
    "# We know that images are 28 pixels in each dimension\n",
    "in_height = 28\n",
    "in_width = 28\n",
    "\n",
    "# Tuple with height and width of images used to reshape arrays\n",
    "image_shape = (in_height, in_width)\n",
    "\n",
    "# We know MNIST has 60.000 training set images\n",
    "num_data_train_images = 60000\n",
    "\n",
    "# We know MNIST has 10.000 training set images\n",
    "num_data_test_images = 10000\n",
    "\n",
    "# Classes info\n",
    "classes = ['0', '1', '2', '3', '4', '5', '6', '7', '8', '9']\n",
    "\n",
    "# Number of classes\n",
    "num_classes = len(classes)\n",
    "\n",
    "# Number of colour channels for the images: 1 channel for gray-scale\n",
    "# Channels mean number of primary colors\n",
    "num_channels = 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load Dataset\n",
    "\n",
    "# The data, split between train and test sets\n",
    "# The datasets are 3D arrays: (batch, height, width)\n",
    "# Returns the values of the function for images_set, labels_set on train-set\n",
    "# Returns the values of the function for images_set, labels_set on test-set\n",
    "(data_train_images, data_train_labels), (data_test_images, data_test_labels) = mnist.load_data()\n",
    "\n",
    "# Our CNN accepts only 4D arrays: (batch, height, width, channels)\n",
    "\n",
    "# Reshape data_train_images \n",
    "data_train_images = data_train_images.reshape(num_data_train_images, in_height, in_width, num_channels)\n",
    "\n",
    "# Reshape data_test_images\n",
    "data_test_images = data_test_images.reshape(num_data_test_images, in_height, in_width, num_channels)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Size of:\n",
      "- Training-set:\t\t60000\n",
      "- Test-set:\t\t10000\n"
     ]
    }
   ],
   "source": [
    "print(\"Size of:\")\n",
    "print(\"- Training-set:\\t\\t{}\".format(len(data_train_images)))\n",
    "print(\"- Test-set:\\t\\t{}\".format(len(data_test_images)))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Codificação One-Hot"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<div style=\"text-align:justify\">As classes que representam os dez digitos manuscritos são representados por valores numéricos.</div>\n",
    "<br>\n",
    "<div style=\"text-align:justify\">Utilizar valores numéricos para representar rótulos categóricos em algoritmos de ML não é considerado como sendo uma boa prática, pois é possível que estes valores gerados possam prejudicar e influenciar a efetividade do algoritmo através do processo de aprendizado.</div>\n",
    "<br>\n",
    "<div style=\"text-align:justify\">Na presença desta restrição, convertemos os valores numéricos que representam os rótulos categóricos (tanto os valores numéricos do conjunto de treinamento quanto os valores numéricos do conjunto de teste) para vetores binários que representam cada um dos valores numéricos, através da codificação One-Hot.</div>\n",
    "<br>\n",
    "<div style=\"text-align:justify\">A codificação One-Hot é uma codificação de estados que consiste em gerar $ n $ vetores binários para $ n $ valores numéricos que representam cada um dos rótulos categóricos. Deste modo, One-Hot realiza a codificação para cada estado, de forma que cada valor numérico seja representado por um único vetor binário de tamanho $ n $ igual a quantidade de classes presentes no conjunto de dados.</div>\n",
    "<br>\n",
    "<div style=\"text-align:justify\">Por exemplo: a saída $ 8 $, de acordo com a codificação One-Hot seria: $ [0, 0, 0, 0, 0, 0, 0, 0, 1, 0] $</div>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[7 2 1 ..., 4 5 6]\n"
     ]
    }
   ],
   "source": [
    "# Class labels are One-Hot coded, meaning that each label is a vector with 10 elements,\n",
    "# all of which are zero except one element\n",
    "data_train_labels = keras.utils.to_categorical(data_train_labels, num_classes)\n",
    "data_test_labels = keras.utils.to_categorical(data_test_labels, num_classes)\n",
    "\n",
    "data_test_cls = np.argmax(data_test_labels, axis=1)\n",
    "\n",
    "print(data_test_cls)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Helper-function for catch the class\n",
    "# number and print its corresponding name\n",
    "def get_number(num_class):\n",
    "    if num_class == 0:\n",
    "        return 'Zero'\n",
    "    elif num_class == 1:\n",
    "        return 'One'\n",
    "    elif num_class == 2:\n",
    "        return 'Two'\n",
    "    elif num_class == 3:\n",
    "        return 'Three'\n",
    "    elif num_class == 4:\n",
    "        return 'Four'\n",
    "    elif num_class == 5:\n",
    "        return 'Five'\n",
    "    elif num_class == 6:\n",
    "        return 'Six'\n",
    "    elif num_class == 7:\n",
    "        return 'Seven'\n",
    "    elif num_class == 8:\n",
    "        return 'Eight'\n",
    "    elif num_class == 9:\n",
    "        return 'Nine'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Helper-function for plotting images\n",
    "def plot_images(images, cls_true, cls_pred=None):\n",
    "    assert len(images) == len(cls_true) == 9\n",
    "    \n",
    "    # Create figure with 3x3 sub-plots\n",
    "    fig, axes = plt.subplots(3, 3)\n",
    "    fig.subplots_adjust(hspace=0.3, wspace=0.3)\n",
    "\n",
    "    for i, ax in enumerate(axes.flat):\n",
    "        # Plot image\n",
    "        ax.imshow(images[i].reshape(image_shape), cmap='gray')\n",
    "\n",
    "        # Show true and predicted classes\n",
    "        # T = True, and P = Predicted\n",
    "        if cls_pred is None:\n",
    "            xlabel = \"T: {0}\".format(get_number(cls_true[i]))\n",
    "        else:\n",
    "            xlabel = \"T: {0}, P: {1}\".format(get_number(cls_true[i]), get_number(cls_pred[i]))\n",
    "\n",
    "        # Show the classes as the label on the x-axis\n",
    "        ax.set_xlabel(xlabel)\n",
    "        \n",
    "        # Remove ticks from the plot\n",
    "        ax.set_xticks([])\n",
    "        ax.set_yticks([])\n",
    "    \n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<matplotlib.figure.Figure at 0x7f3f03fd3128>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Plot a few images to see if data is correct\n",
    "\n",
    "# Get the first images from the test-set\n",
    "images = data_test_images[0:9]\n",
    "\n",
    "# Get the true classes for those images\n",
    "cls_true = data_test_cls[0:9]\n",
    "\n",
    "# Plot the images and labels using our helper-function above\n",
    "plot_images(images=images, cls_true=cls_true)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "# We build a sequential model\n",
    "# The Sequential model is a linear stack of layers\n",
    "model = Sequential()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Camada de Convolução (ou em inglês, Convolutional Layer)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<div style=\"text-align:justify\">É a principal operação que ocorre nas imagens inseridas na rede, e seu principal objetivo está em extrair recursos de imagens de entrada.<br>\n",
    "    \n",
    "<div style=\"text-align:justify\">Uma imagem $ g $ é gerada pela convolução de um filtro $ f $ (comumente conhecido na literatura em inglês como kernel) com a imagem de entrada idefinida pela equação abaixo:<br>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "$$ g(m,n)=\\sum_{i=1}^{q}\\sum_{j=1}^{q}f(i,j)I(m-i,n-j) $$"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<div style=\"text-align:justify\">onde $ q $ é a dimensão da máscara de convolução.</div>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "![Convolução GIF](https://raw.githubusercontent.com/whoisraibolt/Convolutional-Neural-Network-MNIST/master/images/Convolucao-GIF.gif)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<div style=\"text-align:justify\">Um filtro pode ressaltar determinada característica presente em uma imagem, como por exemplo, sombras, bordas, entre outros.</div>\n",
    "<br>\n",
    "<div style=\"text-align:justify\">A Figura abaixo apresenta o resultado de uma convolução aplicada a uma imagem de entrada.</div>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "![Resultado Convolucao](https://raw.githubusercontent.com/whoisraibolt/Convolutional-Neural-Network-MNIST/master/images/Resultado-Convolucao.png)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<div style=\"text-align:justify\">Onde o resultado da convolução é comumente conhecido como um mapa de recursos (em inglês,feature maps), e onde o filtro convolucional $ f $ utilizado foi uma matriz de tamanho $ 3x3 $ como na representação a seguir:</div>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\\begin{equation}\n",
    "\\label{equation:kernel}\n",
    "f = \\begin{bmatrix}\n",
    "1 &0   &0 \\\\ \n",
    "0 &-1  &0 \\\\ \n",
    "0 &0   &0 \n",
    "\\end{bmatrix}  \n",
    "\\end{equation}"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Camada  ReLU (ou em inglês, ReLU Layer)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<div style=\"text-align:justify\">É utilizada para que a rede possa convergir mais rápido, aplica para as camadas escondidas da rede uma função de ativação não linear à saída $ x $ da camada anterior, como abaixo:</div>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\\begin{equation}\n",
    "\\label{equation:relu}\n",
    "f(x) = max(0, x)\n",
    "\\end{equation}"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<div style=\"text-align:justify\">Portanto, a saída será $ 0 $ quando a entrada for menor que $ 0 (x < 0) $, ou a saída será $ 1 $ caso contrário. Desta forma a ativação é limitada exclusivamente a $ 0 $, logo, a função de ativação ReLU contribui em uma etapa de treinamento da rede mais rápida para arquiteturas profundas</div>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Convolutional Layer 1\n",
    "\n",
    "# Convolution filters are 3 x 3 pixels\n",
    "filter_height_1 = 3\n",
    "filter_width_1 = 3\n",
    "\n",
    "# There are 8 of these filters\n",
    "num_filters_1 = 32\n",
    "\n",
    "# Convolutional Layer 2\n",
    "\n",
    "# Convolution filters are 3 x 3 pixels\n",
    "filter_height_2 = 3\n",
    "filter_width_2 = 3\n",
    "\n",
    "# There are 16 of these filters\n",
    "num_filters_2 = 64"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Convolutional Layer 1\n",
    "model.add(Conv2D(filters=num_filters_1,\n",
    "                 kernel_size=(filter_height_1, filter_width_1),\n",
    "                 activation='relu',\n",
    "                 input_shape=(in_height, in_width, num_channels)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Convolutional Layer 2\n",
    "model.add(Conv2D(filters=num_filters_2,\n",
    "                 kernel_size=(filter_height_2, filter_width_2),\n",
    "                 activation='relu'))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Camada de Subamostragem (ou em inglês, Pooling Layer)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<div style=\"text-align:justify\">Reduz a dimensionalidade dos feature maps que serão utilizados pelas camadas seguintes, entretanto, sem perder as informações mais relevantes.  Desta forma,  podemos definir a camada de subamostragem como uma convolução que possui o objetivo de reduzir o tamanho espacial da representação, de forma a contribuir com a diminuição de quantidade de parâmetros e processamento computacional da rede.</div>\n",
    "<br>\n",
    "<div style=\"text-align:justify\">A função do Max-Pooling está em pegar o valor máximo dos elementos do feature maps presentes na janela $ 2x2 $ e agrupa-los como no exemplo abaixo:</div>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "![Max-Pooling](https://raw.githubusercontent.com/whoisraibolt/Convolutional-Neural-Network-MNIST/master/images/Max-Pooling.png)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "# This is 2x2 max-pooling, which means that we\n",
    "# consider 2x2 windows and select the largest value\n",
    "# in each window. Then we move 2 pixels to the next window\n",
    "model.add(MaxPooling2D(pool_size=(2, 2),\n",
    "                       strides=(2, 2)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Dropout randomly switches off some neurons in\n",
    "# the network which forces the data to find new paths\n",
    "model.add(Dropout(0.25))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Camada de Flatten (ou em inglês, Flatten Layer)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<div style=\"text-align:justify\">Após passar pelas camadas de convolução, ReLU e subamostragem a próxima etapa de uma CNN é a classificação, ou seja, é necessário passar pela camada totalmente conectada.  A camada totalmente conectada aceita apenas como entrada, dados de dimensão 1D.</div>\n",
    "<br>\n",
    "<div style=\"text-align:justify\">A camada Flatten possui o objetivo de \"achatar\" todo o volume de dados 3D em um único vetor 1D de características para posteriormente servir de entrada para a camada totalmente conectada.</div>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "# It allows the output to be processed by standard fully connected layers\n",
    "model.add(Flatten())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Camada totalmente conectada (ou em inglês, Fully Connected Layer)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<div style=\"text-align:justify\">Essa camada age como um classificador, se localiza ao final da rede, geralmente é do tipo soft-max usado para classificar a imagem de entrada. Realiza tal tarefa ao reconhecer padrões que foram gerados pelas camadas anteriores. Portanto, estima a probabilidade de quais das $ n $ classes a imagem de entrada pertence.</div>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Fully-connected layer\n",
    "# Number of neurons in fully-connected layer\n",
    "fc_size = 128\n",
    "\n",
    "model.add(Dense(fc_size, activation='relu'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Dropout randomly switches off some neurons in\n",
    "# the network which forces the data to find new paths\n",
    "model.add(Dropout(0.5))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Normalization of class-number output with 10 neurons (number of output classes)\n",
    "# and it uses softmax activation function.\n",
    "# Each neuron will give the probability of that class.\n",
    "#It’s a multi-class classification that’s why softmax activation function\n",
    "model.add(Dense(num_classes, activation='softmax'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define the type of loss function, optimizer and the\n",
    "# metrics evaluated by the model during training and test\n",
    "\n",
    "# Cross Entropy as a Loss function\n",
    "# The lower the loss, the better a model\n",
    "# The loss is calculated on training and its interperation is how well the model is doing for this one set\n",
    "# Loss is not a percentage. It is a summation of the errors made for each example in training  set\n",
    "\n",
    "# AdamOptimizer as optimizer\n",
    "# It is an optimization algorithm used to perform the update of weights\n",
    "# in an iterative way according to the training data set\n",
    "# Needs few memory requirements, in addition to being computationally efficient\n",
    "\n",
    "# and Accuracy as metrics to improve the performance of our neural network\n",
    "\n",
    "model.compile(loss=keras.losses.categorical_crossentropy,\n",
    "              optimizer=keras.optimizers.Adam(),\n",
    "              metrics=['accuracy'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/12\n",
      "60000/60000 [==============================] - 27s 457us/step - loss: 1.7346 - acc: 0.8363\n",
      "Epoch 2/12\n",
      "60000/60000 [==============================] - 10s 163us/step - loss: 0.1262 - acc: 0.9625\n",
      "Epoch 3/12\n",
      "60000/60000 [==============================] - 10s 164us/step - loss: 0.0964 - acc: 0.9708\n",
      "Epoch 4/12\n",
      "60000/60000 [==============================] - 10s 162us/step - loss: 0.0776 - acc: 0.9761\n",
      "Epoch 5/12\n",
      "60000/60000 [==============================] - 10s 163us/step - loss: 0.0677 - acc: 0.9795\n",
      "Epoch 6/12\n",
      "60000/60000 [==============================] - 10s 165us/step - loss: 0.0610 - acc: 0.9808\n",
      "Epoch 7/12\n",
      "60000/60000 [==============================] - 10s 164us/step - loss: 0.0561 - acc: 0.9823\n",
      "Epoch 8/12\n",
      "60000/60000 [==============================] - 10s 164us/step - loss: 0.0486 - acc: 0.9849\n",
      "Epoch 9/12\n",
      "60000/60000 [==============================] - 10s 165us/step - loss: 0.0483 - acc: 0.9847\n",
      "Epoch 10/12\n",
      "60000/60000 [==============================] - 10s 164us/step - loss: 0.0437 - acc: 0.9860\n",
      "Epoch 11/12\n",
      "60000/60000 [==============================] - 10s 164us/step - loss: 0.0462 - acc: 0.9857\n",
      "Epoch 12/12\n",
      "60000/60000 [==============================] - 10s 163us/step - loss: 0.0404 - acc: 0.9871\n"
     ]
    }
   ],
   "source": [
    "# Training\n",
    "\n",
    "# Epoch:\n",
    "# One Epoch is when an ENTIRE dataset is passed forward\n",
    "# and backward through the neural network only ONCE\n",
    "\n",
    "# Batch Size:\n",
    "#Total number of training examples present in a single batch\n",
    "\n",
    "# Iterations:\n",
    "# Iterations is the number of batches needed to complete one epoch\n",
    "\n",
    "# Verbose:\n",
    "# Integer 0, 1, or 2\n",
    "# Verbosity mode: 0 = silent, 1 = progress bar, 2 = one line per epoch\n",
    "\n",
    "batch_size = 128\n",
    "epochs = 12\n",
    "\n",
    "history = model.fit(data_train_images, data_train_labels,\n",
    "                    batch_size=batch_size,\n",
    "                    epochs=epochs,\n",
    "                    verbose=1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Google Cloud Platform"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<div style=\"text-align:justify\">Oferecida pelo Google, o GCP é um conjunto de ferramentas, soluções e serviços de computação em nuvem que atua na mesma infraestrutura central do Google, ao lado de seus produtos, como o YouTube e o seu próprio mecanismo de busca.</div>\n",
    "<br>\n",
    "<div style=\"text-align:justify\">O GCP disponibiliza uma série de soluções para processamento computacional, rede, armazenamento de dados, banco de dados escaláveis, exploração de dados, Internet das Coisas (em inglês,Internet of Things- IoT), ML, ferramentas de gerenciamento, monitoramento, registro, diagnósticos, entre outros.</div>\n",
    "<br>\n",
    "<div style=\"text-align:justify\">Este Notebook foi processado por  meio de uma instância de máquina virtual de alto desempenho na infraestrutura do Google - Google Compute Engine (GCE) - um componente Infraestrutura como Serviço (em inglês, Infrastructure as a Service- IaaS).</div>\n",
    "<br> \n",
    "<div style=\"text-align:justify\">O GCE é um recurso disponível na plataforma Google Cloud Platform (GCP). A instância de máquina virtual on demand é composta por uma GPU NVIDIA® Tesla® K80 com memória da GPU de 12GB GDDR5 e 8 vCPUs disponíveis, além de 16 GB de memória RAM e 50GB de HD e é acessada por meio da interface de linha de comandos.</div>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Test accuracy: 0.9894\n"
     ]
    }
   ],
   "source": [
    "# Test\n",
    "score = model.evaluate(data_test_images, data_test_labels, verbose=0)\n",
    "\n",
    "# Print test accuracy\n",
    "print('Test accuracy:', score[1])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "![Aplausos](https://github.com/whoisraibolt/Convolutional-Neural-Network-MNIST/blob/master/images/Aplausos-GIF.gif?raw=true)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Dicas:"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- [TensorFlow](https://www.tensorflow.org/ \"TensorFlow\");\n",
    "- [Keras](https://keras.rstudio.com/index.html \"Keras\");\n",
    "- [An Intuitive Explanation of Convolutional Neural Networks](https://ujjwalkarn.me/2016/08/11/intuitive-explanation-convnets \"An Intuitive Explanation of Convolutional Neural Networks\");\n",
    "- [Hvass-Labs](https://github.com/Hvass-Labs/TensorFlow-Tutorials \"Hvass-Labs\");\n",
    "- [How to set up Tensorflow with CUDA and cuDNN on a free Google Cloud instance](https://www.youtube.com/watch?v=abEf3wQJBmE \"How to set up Tensorflow with CUDA and cuDNN on a free Google Cloud instance\")."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Leituras Recomendadas:"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- BEALE, Russell; JACKSON, Tom. [Neural Computing-an introduction](https://bayanbox.ir/view/7901640340179926235/Neural-Computing-An-Introduction.pdf \"Neural Computing-an introduction\"). CRC Press, 1990."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Referências:"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- [Towards Data Science](https://towardsdatascience.com/build-your-own-convolution-neural-network-in-5-mins-4217c2cf964f \"Towards Data Science\");\n",
    "- [Hvass-Labs](https://github.com/Hvass-Labs/TensorFlow-Tutorials/blob/master/02_Convolutional_Neural_Network.ipynb \"Hvass-Labs\")."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Distribuição MIT"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Código lançado sob a licença [MIT](https://github.com/whoisraibolt/Convolutional-Neural-Network-MNIST/blob/master/LICENSE \"MIT\")."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
